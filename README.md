# Deep Learning Fundamentals (Python)

This repository contains my implementations and solutions for the [Deep Learning](https://opiskelijanopas.tuni.fi/en/tampere-university/curriculum/course-units/tut-cu-g-42119?year=2025) course completed at Tampere University.

The course focuses on the mathematical foundations and engineering implementation of modern neural networks, from single neurons to Transformer architectures.

---

## Overview

Deep learning is a core technology in modern artificial intelligence.  
This repository demonstrates practical implementations of neural network models using Python, covering both theory and applied engineering.  
To get started with the exercises, check out the *[Setup & Getting Started Guide](https://github.com/theanasuddin/Deep-Learning-Fundamentals/blob/master/GETTING_STARTED.md)*

The exercises emphasize:

- Understanding how deep learning models work internally
- Implementing architectures from scratch
- Applying training algorithms correctly
- Building models for supervised learning tasks

---

## Topics Covered

### Week 1 — Multilayer Perceptrons
- Linear classification & perceptrons
- Nonlinear activations
- Loss functions
- Gradient descent & stochastic gradient descent
- Backpropagation fundamentals

### Week 2 — Convolutional Neural Networks
- Convolutional layers
- Pooling & subsampling
- Translation invariance
- Training CNN models

### Week 3 — Deep Architectures & Mechanisms
- Architectural design principles
- Representation learning concepts

### Week 4 — Recurrent Neural Networks
- Sequence modeling
- Temporal dependencies
- RNN training challenges

### Week 5 — Attention & Transformers
- Attention mechanisms
- Self-attention
- Transformer architecture fundamentals

### Week 6 — Generative Modeling & Transfer Learning
- Generative approaches
- Model reuse and fine-tuning strategies

---

## Technologies Used

- Python
- NumPy
- Deep learning frameworks (where applicable)
- Jupyter Notebooks
- Gradient-based optimization techniques

---

## Repository Structure

Each folder contains implementation notebooks and related files for that week's exercises.

---

## Learning Outcomes

Through this course, I strengthened my ability to:

- Derive and implement backpropagation
- Build and train neural networks from first principles
- Understand architectural trade-offs
- Apply attention mechanisms and Transformer models
- Connect mathematical theory to practical model implementation

---

## Note

This repository contains my personal implementations of coursework exercises.  
No confidential materials or restricted content are included.
